{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Detectron2 installation**"
      ],
      "metadata": {
        "id": "zw97RgZvLsst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install pyyaml==5.1\n",
        "!pip install CocoDataset==0.1.2\n",
        "import sys, os, distutils.core\n",
        "# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities.\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n",
        "!git clone 'https://github.com/facebookresearch/detectron2'\n",
        "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
        "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
        "sys.path.insert(0, os.path.abspath('./detectron2'))\n",
        "\n",
        "# Properly install detectron2. (Please do not install twice in both ways)\n",
        "# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ],
      "metadata": {
        "id": "Ye8jEPlNLtCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]"
      ],
      "metadata": {
        "id": "FGOlihqGMtCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Import libraries**"
      ],
      "metadata": {
        "id": "2dSWzSR0pD7X"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyAvNCJMmvFF"
      },
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "import copy\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dq9GY37ml1kr"
      },
      "source": [
        "im = cv2.imread(\"/content/bus/COCO_train2014_000000049254.jpg\")\n",
        "cv2_imshow(im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Download dataset** - REMOVE!"
      ],
      "metadata": {
        "id": "zuaqiRWvpZ9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# args = sys.argv\n",
        "# args = [\"http://images.cocodataset.org/annotations/annotations_trainval2014.zip\",\n",
        "#         \"/content/annotations_trainval2014.zip\",\n",
        "#         \"http://images.cocodataset.org/zips/train2014.zip\",\n",
        "#         \"/content/train2014.zip\"\n",
        "#         ]\n",
        "\n",
        "args = [\"http://images.cocodataset.org/annotations/annotations_trainval2014.zip\",\n",
        "        \"/content/annotations_trainval2014.zip\",\n",
        "        \"http://images.cocodataset.org/zips/train2014.zip\",\n",
        "        \"/content/train2014.zip\"\n",
        "        ]\n",
        "\n",
        "annotations_link = args[0]\n",
        "annotations_unzip_path = args[1]\n",
        "images_link = args[2]\n",
        "images_unzip_path = args[3]\n",
        "\n",
        "!wget \"http://images.cocodataset.org/annotations/annotations_trainval2014.zip\"\n",
        "!unzip \"/content/annotations_trainval2014.zip\"\n",
        "\n",
        "!wget \"http://images.cocodataset.org/zips/train2014.zip\"\n",
        "!unzip \"/content/train2014.zip\"\n",
        "\n",
        "!wget \"http://images.cocodataset.org/zips/val2014.zip\"\n",
        "!unzip \"/content/val2014.zip\"\n",
        "\n",
        "# from coco_dataset import coco_dataset_download as cocod\n",
        "# class_name='bus'  #class name example \n",
        "# # images_count=50       #count of images  \n",
        "# annotations_path= '/content/annotations/instances_train2014.json' #path of coco dataset annotations \n",
        "# #call download function \n",
        "# cocod.coco_dataset_download(class_name,images_count,annotations_path)"
      ],
      "metadata": {
        "id": "gqiGcPNVpWqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Augmentation class\n",
        "\n",
        "\n",
        "*   Sky cropping\n",
        "*   List item\n",
        "\n"
      ],
      "metadata": {
        "id": "28hjX9e9p9eT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Data_Augmentation:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.segmentation_pred = None\n",
        "    # self.detection_pred = None\n",
        "    self.data_set = None\n",
        "\n",
        "  def __predictor_init(self):\n",
        "    cfg = get_cfg()\n",
        "    # initialize segementation model\n",
        "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml\"))\n",
        "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml\")\n",
        "    self.segmentation_pred = DefaultPredictor(cfg)\n",
        "    # initialize detection model\n",
        "    # cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "    # cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
        "    # cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "    # self.detection_pred = DefaultPredictor(cfg)\n",
        "  \n",
        "  def sky_crop(self, img_dict):\n",
        "    self.__predictor_init()\n",
        "    img = cv2.imread(img_dict[\"file_name\"])\n",
        "    # run inference on image\n",
        "    panoptic_seg, segments_info = self.segmentation_pred(img)[\"panoptic_seg\"]\n",
        "    # outputs = self.detection_pred(img)\n",
        "    # finding label corresponding to sky\n",
        "    id = 0\n",
        "    for dict in segments_info:\n",
        "      if dict['category_id'] == 40:\n",
        "        id = dict['id']\n",
        "    if id == 0:\n",
        "      print(\"no sky detected\")\n",
        "      self.__update_seg(0, img_dict['annotations'])\n",
        "      return img_dict\n",
        "    # creating mask on sky\n",
        "    panoptic_seg = panoptic_seg.cpu()\n",
        "    mask = np.where(panoptic_seg==id, 1, 0)\n",
        "    # finding max sky pixel\n",
        "    y_ind, x_ind = np.where(mask==1)\n",
        "    max_y = y_ind[-1]\n",
        "    # cropping image\n",
        "    cropped_img = img[max_y:, :, :]\n",
        "    # Save the image\n",
        "    image_name = \"/content/sky_cropped/new_image\" + str(img_dict['image_id']) + \".jpg\"\n",
        "    path = 'sky_cropped'\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    cv2.imwrite(image_name, cropped_img)\n",
        "    img_dict['file_name'] = image_name\n",
        "    img_dict['height'] = cropped_img.shape[0]\n",
        "    img_dict['width'] = cropped_img.shape[1]\n",
        "    # fix bboxes\n",
        "    img_dict['annotations'] = self.__update_boxes(max_y, img_dict['annotations'])\n",
        "    self.__update_seg(max_y, img_dict['annotations'])\n",
        "    return img_dict\n",
        "    \n",
        "  def __update_boxes(self, max_y, boxes):\n",
        "    new_dicts = []\n",
        "    # going through all dicts and for each one update bbox\n",
        "    for i in range(len(boxes)):\n",
        "      x_min, y_min, width, height = boxes[i]['bbox']  \n",
        "      if max_y <= y_min:\n",
        "        boxes[i]['bbox'][1] = int(y_min - max_y)\n",
        "        new_dicts.append(boxes[i])\n",
        "        continue\n",
        "      if max_y < y_min+height:\n",
        "        boxes[i]['bbox'][3] = int(y_min+height - max_y)\n",
        "        boxes[i]['bbox'][1] = 0\n",
        "        new_dicts.append(boxes[i])\n",
        "    return new_dicts\n",
        "\n",
        "  def __update_seg(self, max_y, boxes):\n",
        "  # new_dicts = []\n",
        "  # going through all dicts and for each one update bbox\n",
        "    for i in range(len(boxes)):\n",
        "      boxes[i]['segmentation'] = []\n",
        "      # arr = boxes[i]['segmentation']\n",
        "      # for j in range(0, len(arr[0])-2, 2): \n",
        "      #   # print(j)\n",
        "      #   curr_y = arr[0][j] \n",
        "      #   if max_y <= curr_y:\n",
        "      #     arr[0][j] = curr_y - max_y\n",
        "      #     # new_dicts.append(boxes[i])\n",
        "      #     continue\n",
        "      #   if curr_y < max_y:\n",
        "      #     arr[0][j] = 0\n",
        "          # new_dicts.append(boxes[i])\n",
        "    # return new_dicts\n",
        "      \n",
        "        "
      ],
      "metadata": {
        "id": "ucdE7ilgH8yF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Registering coco dataset \n",
        "assuming this dataset is in COCO format\n",
        "\n"
      ],
      "metadata": {
        "id": "DNl5DImQlRXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.structures import BoxMode\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "args = [\n",
        "        \"/content/annotations/instances_train2014.json\",\n",
        "        \"/content/train2014\",\n",
        "        \"My_dataset2\",\n",
        "        \"/content/sky_cropped/new_image.jpg\",\n",
        "        \"/content/annotations/sky_crop_annotations.json\"\n",
        "        ]\n",
        "\n",
        "path_to_annotations = args[0]\n",
        "path_to_images = args[1]\n",
        "dataset_name = args[2]\n",
        "path_to_new_images = args[3]\n",
        "path_to_new_annotations = args[4]\n",
        "register_coco_instances(dataset_name, {}, path_to_annotations, path_to_images)"
      ],
      "metadata": {
        "id": "LUhLhWRlkvBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading annotations"
      ],
      "metadata": {
        "id": "5x1D3RhxqZ6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.data.datasets import load_coco_json\n",
        "# Load the image and annotation data for the \"my_dataset2_train\" dataset\n",
        "dataset_dicts = load_coco_json(path_to_annotations, path_to_images, dataset_name)\n",
        "# Get the first image and annotation in the dataset\n",
        "metadata = MetadataCatalog.get(dataset_name)"
      ],
      "metadata": {
        "id": "0oX2koGt7eYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Single photo example"
      ],
      "metadata": {
        "id": "R2wrwRRYzEYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "d = None\n",
        "for i in range(len(dataset_dicts)):\n",
        "  if dataset_dicts[i][\"file_name\"] == \"/content/train2014/COCO_train2014_000000000049.jpg\":\n",
        "    d = copy.deepcopy(dataset_dicts[i])\n",
        "    print(\"Found it!\")\n",
        "    break\n",
        "aug = Data_Augmentation()\n",
        "curr_dict = dataset_dicts[i]\n",
        "new_dict = aug.sky_crop(d)\n",
        "img = cv2.imread(new_dict['file_name'])\n",
        "annotations = new_dict['annotations']\n",
        "visualizer = Visualizer(img[:, :, ::-1], metadata=metadata, scale=1)\n",
        "out = visualizer.draw_dataset_dict(new_dict)\n",
        "cv2_imshow(out.get_image()[:, :, ::-1])\n"
      ],
      "metadata": {
        "id": "ajpsxwoLkhM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "multiple images"
      ],
      "metadata": {
        "id": "oNhPTN4r87O5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for every dict from the list perform sky_crop then vizualize\n",
        "aug = Data_Augmentation()\n",
        "for i in range(len(dataset_dicts)):\n",
        "  curr_dict = dataset_dicts[i]\n",
        "  new_dict = aug.sky_crop(curr_dict)\n",
        "  img = cv2.imread(curr_dict['file_name'])\n",
        "  visualizer = Visualizer(img[:, :, ::-1], metadata=metadata, scale=1)\n",
        "  out = visualizer.draw_dataset_dict(curr_dict)\n",
        "  cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "metadata": {
        "id": "Xza-_IFksLlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving json"
      ],
      "metadata": {
        "id": "0S3Aiu7_M2-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(path_to_new_annotations, \"w\") as f:\n",
        "    # Write the list of dictionaries to the file as JSON\n",
        "    json.dump(dataset_dicts, f)"
      ],
      "metadata": {
        "id": "wz35gxtYM1_m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}